{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.cross_validation import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_dir = '../kaggle_data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kaggle_train = data_dir+'train.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_orig = pd.read_csv(kaggle_train)\n",
    "import copy\n",
    "df = copy.copy(df_orig)\n",
    "#df_train,df_cv = train_test_split(pd.read_csv(kaggle_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27300"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(df[df['target']==0])\n",
    "N = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#df_train.sortlevel()\n",
    "\n",
    "# df['null_count'] = df.isnull().sum(axis=1)\n",
    "# df = df[df['null_count']<10]\n",
    "# df.drop('null_count',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# BALANCE THE CLASSES\n",
    "\n",
    "mask1 = df['target']==1\n",
    "mask0 = df['target']==0\n",
    "#N = 5000\n",
    "df = pd.concat([df[mask1].sample(N), df[mask0].sample(N)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df = df.sample(frac=0.1)\n",
    "# len(df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "person_id = df['ID']\n",
    "y_df = df['target']\n",
    "y_df_orig = df_orig['target']\n",
    "y_df.index = df['ID']\n",
    "y_df_orig.index = df_orig['ID']\n",
    "category_features = ['v24','v30','v31','v47','v52','v56','v66',\\\n",
    "                     'v74','v75','v79','v91','v107','v110','v112','v113','v125']\n",
    "complicated_category_features = ['v3','v22','v52','v71']\n",
    "integer_features = ['v38','v62','v72','v129']\n",
    "\n",
    "non_numeric = ['ID','target']+category_features+complicated_category_features\n",
    "numeric_features = []\n",
    "for c in df.columns:\n",
    "    if c not in non_numeric:\n",
    "        numeric_features.append(c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df[integer_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_cat = df[category_features]\n",
    "df_cat_orig = df_orig[category_features]\n",
    "df_cat.index = df['ID']\n",
    "df_cat_orig.index = df_orig['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # OPTIONAL: FILL NANS WITH MODE OF GROUP\n",
    "# for c in df_cat.columns.values:\n",
    "#     df_cat[c] = df_cat[c].fillna(df_cat[c].mode())\n",
    "df_cat = pd.get_dummies(df_cat,dummy_na=True)\n",
    "df_cat_orig = pd.get_dummies(df_cat_orig,dummy_na=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for c in df_cat.columns.values:\n",
    "#     print(c)\n",
    "#     print(df_cat[c].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_num = df[numeric_features]\n",
    "df_num_orig = df_orig[numeric_features]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "for c in df_num.columns.values:\n",
    "    df_num[c] = df_num[c].fillna(df_num[c].mean())\n",
    "    df_num_orig[c] = df_num_orig[c].fillna(df_num_orig[c].mean())\n",
    "df_num.index = df['ID']\n",
    "df_num_orig.index = df_orig['ID']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df = df_num.merge(df_cat,how='inner',left_index=True,right_index=True)\n",
    "X_df_orig = df_num_orig.merge(df_cat_orig,how='inner',left_index=True,right_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_df['Target'] = y_df.values\n",
    "X_df_orig['Target'] = y_df_orig.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_train,df_test = train_test_split(X_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_df_train = df_train['Target']\n",
    "X_df_train = df_train.drop(['Target'],axis=1)\n",
    "y_df_test = df_test['Target']\n",
    "X_df_test = df_test.drop(['Target'],axis=1)\n",
    "X_df_orig = X_df_orig.drop(['Target'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = X_df_train.values\n",
    "y_train = y_df_train.values\n",
    "X_test = X_df_test.values\n",
    "y_test = y_df_test.values\n",
    "X_orig = X_df_orig.values\n",
    "\n",
    "# X_train = X_df_train[imp_features].values\n",
    "# y_train = y_df_train.values\n",
    "# X_test = X_df_test[imp_features].values\n",
    "# y_test = y_df_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier as XGBC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clf = LogisticRegression(C=0.01)\n",
    "#clf = RandomForestClassifier(max_depth=13)\n",
    "clf = XGBC(learning_rate=0.02,n_estimators=300,max_depth=7)\n",
    "clf.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Predictions on training\n",
    "print(\"TRAINING SET:\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = sns.heatmap(confusion_matrix(clf.predict(X_train),y_train))\n",
    "ax.set_xlabel('Input')\n",
    "ax.set_ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Predictions on test\n",
    "print(\"TEST SET:\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = sns.heatmap(confusion_matrix(clf.predict(X_test),y_test))\n",
    "ax.set_xlabel('Input')\n",
    "ax.set_ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "# Predictions on unbalanced set\n",
    "print(\"UNBALANCED SET:\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = sns.heatmap(confusion_matrix(clf.predict(X_orig),y_orig))\n",
    "ax.set_xlabel('Input')\n",
    "ax.set_ylabel('Prediction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "clf.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "perc_balance = 1.0*len(df_orig[df_orig['target']==1].index) / (len(df_orig[df_orig['target']==0].index)+\\\n",
    "                                                    len(df_orig[df_orig['target']==1].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chance_0 = clf.predict_proba(X_test)[:,0]\n",
    "\n",
    "\n",
    "zeros = np.where(chance_0>np.percentile(chance_0,perc_balance*100))\n",
    "ones  = np.where(chance_0<=np.percentile(chance_0,perc_balance*100))\n",
    "\n",
    "# unbalanced_set = np.ones(len(X_test))\n",
    "# unbalanced_set[zeros]=0\n",
    "\n",
    "chance_0 = chance_0**2\n",
    "\n",
    "zeros = np.where(chance_0>np.percentile(chance_0,50))\n",
    "ones  = np.where(chance_0<=np.percentile(chance_0,50))\n",
    "\n",
    "unbalanced_set = np.ones(len(X_test))\n",
    "unbalanced_set[zeros]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Predictions on test\n",
    "print(\"TEST SET:\")\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix\n",
    "ax = sns.heatmap(confusion_matrix(unbalanced_set,y_test))\n",
    "ax.set_xlabel('Input')\n",
    "ax.set_ylabel('Prediction')\n",
    "plt.show()\n",
    "\n",
    "print(confusion_matrix(unbalanced_set,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "1.0*np.sum(unbalanced_set==y_test) / np.size(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "importances = clf.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in clf.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "cols = X_df_train.columns.values\n",
    "# Print the feature ranking\n",
    "print(\"Feature ranking:\")\n",
    "\n",
    "for f in range(X.shape[1]):\n",
    "    print(\"%d. feature %s (%f)\" % (f + 1, cols[indices[f]], importances[indices[f]]))\n",
    "\n",
    "# Plot the feature importances of the forest\n",
    "plt.figure()\n",
    "plt.title(\"Feature importances\")\n",
    "\n",
    "lim = -1\n",
    "plt.bar(range(X_train.shape[1])[:lim], importances[indices][:lim],\n",
    "       color=\"r\", yerr=std[indices][:lim], align=\"center\")\n",
    "plt.xticks(range(X_train.shape[1])[:lim], np.array(cols)[indices[:lim]])\n",
    "plt.xlim([-1, max(np.arange(X_train.shape[1])[:lim])])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# imp_features = cols[importances>0.002]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
